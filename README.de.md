[![en](https://img.shields.io/badge/lang-en-red.svg)](https://github.com/Shegzimus/shegzimus/blob/main/README.md)

## ğŸŒŸ Ãœber mich
âš™ï¸ Data Engineer mit Erfahrung im Aufbau modularer cloudbasierter ETL-Pipelines fÃ¼r Cloud-Plattformen.
ğŸ”¢ Akademischer Hintergrund in Mathematik (B.Sc.) & Data Science (M.Sc.)
ğŸ’¼ Kurze Laufbahn im Management & Public Health Consulting
ğŸ’» Leidenschaftlich an Datenpipeline-Entwicklung und containerisierten Workflows interessiert.

ğŸ› ï¸ Tech-Stack: [![My Skills](https://skillicons.dev/icons?i=py,r,terraform,postgres,bash,docker,redis,github,git,gcp,aws,kafka,latex,vscode,windows )](https://skillicons.dev)
SpezialitÃ¤t: Schreiben von gut lesbaren & refakturierbaren ETL-Skripten/-Modulen sowie Konfiguration von virtuellen Maschinen und Docker-Images/Containern.
ğŸ’¡ Meine Designphilosophie (was du erwarten kannst)
Skalierbare und delegierbare Pipelines: Ich bin der Meinung, dass Pipelines so gestaltet sein sollten, dass sie leicht zu bedienen und zu warten sind, damit sich Teams auf die Entwicklung neuer LÃ¶sungen und die LÃ¶sung anderer Herausforderungen konzentrieren kÃ¶nnen. Dieser Ansatz steht im Gegensatz zu der verbreiteten Annahme, dass nur der Autor seinen Code warten kann. Gute Pipelines erfordern nach der Bereitstellung wenig bis gar kein Eingreifen des Autors.

FunktionalitÃ¤t vor Verfeinerung: Ich setze darauf, Dinge schnell an den Start zu bringen und zuerst eine funktionierende Pipeline zu erstellen â€“ um schnell Mehrwert zu liefern â€“, bevor man sie in eine umfassendere, zukunftssichere Version verfeinert. Das spart Zeit und ermÃ¶glicht es mir, das Design anhand von praktischen RÃ¼ckmeldungen anzupassen.

Sicherheit und ModularitÃ¤t als Grundpfeiler: Sichere und modulare Designs sind fÃ¼r meine Arbeit von zentraler Bedeutung. Ich lege (manchmal vielleicht zu viel) Wert auf die Umsetzung von Best Practices wie Secret Management, nicht fest codierten Pfaden und modularen Strukturen, um Pipelines robust, konform und pflegeleicht zu gestalten.

ğŸ”­ Woran ich gerade arbeite
Apache Spark & PySpark-Optimierungen
dbt (Data Build Tool) & Analytics Engineering
MLOps & Feature Engineering fÃ¼r ML-Pipelines
JVM-Sprachen (Java & Scala)
ğŸ“« Kontakt
