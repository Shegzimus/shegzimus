# ğŸ‘‹ Hi! I'm Oluwasegun but for ease of conversation please call me Viktor

## ğŸŒŸ About Me
- âš™ï¸ **Data Engineer** skilled in building robust and scalable ETL pipelines for cloud platforms like AWS and GCP.
- ğŸ”¢ **Academic background in Mathematics & Data Science** with proven abilities in problem-solving and abstract thinking.
- ğŸ’¼ **Brief career in Management & Public Health Consulting** where I delivered data-driven solutions across various industries.
- ğŸ’» Passionate about **data pipeline development**, and **containerized workflows**.

## ğŸ› ï¸ My Skills
- **Programming Languages**: Python, SQL, PySpark, HCL.
- **Tools & Technologies**: Docker, Airflow, Terraform, AWS (S3, Glue, EC2), GCP (BigQuery, Storage, Cloud Run).
- **Strengths**: Seeing the bigger picture, abstracting ideas and **representing client/manager expectations during the solution design process**.

## ğŸ’¡ Design Philosophy
- **Scalable and Delegable Pipelines**: I believe in designing pipelines that are intuitive to operate and delegate,
  enabling teams to focus on creating new solutions and solving other challenges. This approach contrasts with the common
  belief that only the author can maintain their code. I believe that good pipelines require little to no author intervention during production.
  
- **Functionality before refinement**: I believe in getting things off the ground and starting with a pipeline that worksâ€”delivering value quicklyâ€”before refining it into a more polished, future-proof version. This saves time and lets me adapt designs based on real-world feedback.
  
- **Security and Modularity as Cornerstones**: Secure and modular designs are fundamental to my work. I focus (too much sometimes) on implementing
  best practices like secret management, non-hardcoded paths, and modular structures to ensure pipelines are robust, compliant, and easy to maintain.

## ğŸ”­ What Iâ€™m Working On
- Developing a real-time streaming pipeline using tools like Kafka and Apache Flink to process and analyze weather data.
- Building pipelines with dynamic workload management capabilities using Airflow and Spark to adjust resource allocation based on data volume and complexity.
- Implementing real-time CDC pipelines using Debezium to track and stream database changes to a cloud data warehouse

## ğŸ“ˆ Recent Projects
- **[WooCommerce Data Pipeline](#)**: A modular pipeline for extracting, transforming, and loading e-commerce data.
- **[Real Estate ETL](#)**: End-to-end ETL pipeline for processing real estate sales data (2001-2020).
- **[Flight Delay Prediction](#)**: A machine learning model for predicting flight delays using historical data.

## ğŸ“« Connect With Me
If you find these qualities helpful, I'll be happy to discuss how I can add value to your team/project!
- ğŸ“§ *[Email](segun.ajet@protonmail.com)*
- ğŸ¦œ *[Book a brief meeting](https://calendar.app.google/zEJVh3RVoMRD3odn6)*
- ğŸ’¼ *[LinkedIn](https://www.linkedin.com/in/segun-ajet/)*
